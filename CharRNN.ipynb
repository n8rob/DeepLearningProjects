{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Nate_Robinson_DL_Lab6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cksgAH12XRjV"
      },
      "source": [
        "# Char-RNN Implementation (sequence-to-sequence model)\n",
        "\n",
        "## Description:\n",
        "We code up the [char-rnn model of Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/). This is a recurrent neural network that is trained probabilistically on sequences of characters, and that can then be used to sample new sequences that are like the original.\n",
        "\n",
        "## There are two parts of this lab:\n",
        "###  1.   Wiring up a basic sequence-to-sequence computation graph\n",
        "###  2.   Implementing custom GRU cell.\n",
        "\n",
        "\n",
        "An example of some final samples from an equivalent implementation are shown below (more detail in the\n",
        "final section of this writeup), after 150 passes through the data.\n",
        "We generate about 15 samples for each dataset.\n",
        "\n",
        "<code>\n",
        "And ifte thin forgision forward thene over up to a fear not your\n",
        "And freitions, which is great God. Behold these are the loss sub\n",
        "And ache with the Lord hath bloes, which was done to the holy Gr\n",
        "And appeicis arm vinimonahites strong in name, to doth piseling \n",
        "And miniquithers these words, he commanded order not; neither sa\n",
        "And min for many would happine even to the earth, to said unto m\n",
        "And mie first be traditions? Behold, you, because it was a sound\n",
        "And from tike ended the Lamanites had administered, and I say bi\n",
        "</code>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7bdZWxvJrsx"
      },
      "source": [
        "# ! wget -O ./text_files.tar.gz 'https://piazza.com/redirect/s3?bucket=uploads&prefix=attach%2Fjlifkda6h0x5bk%2Fhzosotq4zil49m%2Fjn13x09arfeb%2Ftext_files.tar.gz' \n",
        "# ! tar -xzf text_files.tar.gz\n",
        "# ! pip install unidecode\n",
        "# ! pip install torch\n",
        "\n",
        "import unidecode\n",
        "import string\n",
        "import random\n",
        "import re\n",
        " \n",
        "import pdb\n",
        " \n",
        "all_characters = string.printable\n",
        "n_characters = len(all_characters)\n",
        "# file = unidecode.unidecode(open('./text_files/lotr.txt').read())\n",
        "# file_len = len(file)\n",
        "# print('file_len =', file_len)\n",
        "\n",
        "CUDA_LAUNCH_BLOCKING=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d111-VqIl8Cu",
        "outputId": "7f8c7887-4da3-4776-a012-943aab947369",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "import io\n",
        "def upload():\n",
        "  print('Upload Text')\n",
        "  file_dict = files.upload()\n",
        "  content_path = io.BytesIO(file_dict[next(iter(file_dict))])\n",
        "  return content_path\n",
        "\n",
        "content_path_text = upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Upload Text\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4b95f603-9364-467c-b43d-623da57efa69\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-4b95f603-9364-467c-b43d-623da57efa69\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving christmas_carol.txt to christmas_carol (12).txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bJt1l3QmgT2",
        "outputId": "46c6f729-fcdd-4010-90db-abe941a06dcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "file = content_path_text.read()\n",
        "file = str(file).replace(\"\\\\r\\\\n\",'\\n')\n",
        "file = unidecode.unidecode(file)\n",
        "file_len = len(file)\n",
        "print('file_len =', file_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "file_len = 178293\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxBeKeNjJ0NQ",
        "outputId": "f74302dd-1bca-4e41-c9c7-03bf37a7ed16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "chunk_len = 200\n",
        " \n",
        "def random_chunk():\n",
        "  start_index = random.randint(0, file_len - chunk_len)\n",
        "  end_index = start_index + chunk_len + 1\n",
        "  return file[start_index:end_index]\n",
        "  \n",
        "print(random_chunk())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "arth swept, and the fire made up. The compound in the\n",
            "jug being tasted, and considered perfect, apples and oranges\n",
            "were put upon the table, and a shovel-full of chestnuts on the\n",
            "fire. Then all the Crat\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "On0_WitWJ99e",
        "outputId": "02a6a554-e860-4da5-d095-27916fc34c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Variable\n",
        "# Turn string into list of longs\n",
        "def char_tensor(string):\n",
        "  tensor = torch.zeros(len(string)).long() #FIXME: CUDA?\n",
        "  for c in range(len(string)):\n",
        "      tensor[c] = all_characters.index(string[c])\n",
        "  return Variable(tensor.cuda())\n",
        "\n",
        "print(char_tensor('abcDEF'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([10, 11, 12, 39, 40, 41], device='cuda:0')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYJPTLcaYmfI"
      },
      "source": [
        "---\n",
        "\n",
        "## Creating our own GRU cell \n",
        "\n",
        "---\n",
        "\n",
        "We write our own GRU class using the same parameters as the built-in Pytorch class does.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavAv50ZKQ-F"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.nn.parameter import Parameter\n",
        "\n",
        "\n",
        "class GRU(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_layers):\n",
        "    super(GRU, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "    \n",
        "    self.lin_ir = nn.Linear(input_size, hidden_size).cuda()\n",
        "    self.lin_hr = nn.Linear(hidden_size, hidden_size).cuda()\n",
        "    self.lin_iz = nn.Linear(input_size, hidden_size).cuda()\n",
        "    self.lin_hz = nn.Linear(hidden_size, hidden_size).cuda()\n",
        "    self.lin_in = nn.Linear(input_size, hidden_size).cuda()\n",
        "    self.lin_hn = nn.Linear(hidden_size, hidden_size).cuda()\n",
        "  \n",
        "  def forward(self, inputs, hidden):\n",
        "    # Each layer does the following:\n",
        "    # r_t = sigmoid(W_ir*x_t + b_ir + W_hr*h_(t-1) + b_hr)\n",
        "    # z_t = sigmoid(W_iz*x_t + b_iz + W_hz*h_(t-1) + b_hz)\n",
        "    # n_t = tanh(W_in*x_t + b_in + r_t**(W_hn*h_(t-1) + b_hn))\n",
        "    # h_(t) = (1 - z_t)**n_t + z_t**h_(t-1)\n",
        "    # Where ** is hadamard product (not matrix multiplication, but elementwise multiplication)\n",
        "    \n",
        "    # We are at time 0\n",
        "    x = inputs.cuda()\n",
        "    h = hidden.cuda()\n",
        "#     h_s = h\n",
        "    r = torch.sigmoid(self.lin_ir(x) + self.lin_hr(h)).cuda()\n",
        "    z = torch.sigmoid(self.lin_iz(x) + self.lin_hz(h)).cuda()\n",
        "    n = torch.tanh(self.lin_in(x) + r*self.lin_hn(h)).cuda()\n",
        "    h = (1-z)*n + z*h  \n",
        "#       x = h\n",
        "#       hs = torch.cat(hs,h,dim=1)\n",
        "    \n",
        "    outputs = h.cuda()\n",
        "    hiddens = h.cuda()\n",
        "    return outputs, hiddens\n",
        "  \n",
        "# Embeddings model \n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtXdX-B_WiAY"
      },
      "source": [
        "---\n",
        "\n",
        "##  Building a sequence to sequence model\n",
        "\n",
        "---\n",
        "\n",
        "Great! We have the data in a useable form. We can switch out which text file we are reading from, and trying to simulate.\n",
        "\n",
        "We now want to build out an RNN model, in this section, we will use all built in Pytorch pieces when building our RNN class.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6tNdEnzWj5F"
      },
      "source": [
        "class RNN(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, output_size, dim_vocab, n_layers=1):\n",
        "    super(RNN, self).__init__()\n",
        "    self.input_size = input_size\n",
        "    self.hidden_size = hidden_size\n",
        "    self.output_size = output_size\n",
        "    self.dim_vocab = dim_vocab\n",
        "    self.n_layers = n_layers\n",
        "    \n",
        "#     self.W_hh = nn.Linear(hidden_size,hidden_size)\n",
        "#     self.W_xh = nn.Linear(input_size,hidden_size)\n",
        "#     self.W_hy = nn.Linear(hidden_size,output_size)\n",
        "    \n",
        "    self.embedding = nn.Embedding(input_size, dim_vocab).cuda()\n",
        "    self.gru = GRU(input_size, hidden_size, n_layers)# nn.GRU(input_size=dim_vocab, hidden_size=hidden_size, num_layers=n_layers).cuda()\n",
        "    self.lin = nn.Linear(hidden_size, output_size).cuda() # \n",
        "\n",
        "  def forward(self, inp, hidden):\n",
        "    # by reviewing the documentation, construct a forward function that properly uses the output\n",
        "    # of the GRU\n",
        "    embedded = self.embedding(inp).view(1, 1, -1)\n",
        "#     print(\"Yo embed yo\")\n",
        "    embedded = F.relu(embedded.cuda())\n",
        "#     pdb.set_trace() # Good spot to de-bug\n",
        "    for t in range(self.n_layers):\n",
        "      out, hidden = self.gru(embedded, hidden)\n",
        "      out = self.lin(out[0])\n",
        "      embedded = F.relu(out.cuda())\n",
        "    \n",
        "    return out, hidden\n",
        "\n",
        "  def init_hidden(self):\n",
        "    return Variable(torch.zeros(self.n_layers, 1, self.hidden_size).cuda())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hrhXghEPKD-5"
      },
      "source": [
        "def random_training_set(): \n",
        "  \"\"\" This fcn returns two tensors that are our encoded tokens (but not embedded)\n",
        "  \"\"\"\n",
        "  chunk = random_chunk()\n",
        "  chunk = chunk.replace(\"\\\\r\\\\n\",'\\n')\n",
        "#   pdb.set_trace()\n",
        "  inp = char_tensor(chunk[:-1]) # What we put in (all but last char)\n",
        "\n",
        "  target = char_tensor(chunk[1:]) # What we hope to get out (from second to last char)\n",
        "  return inp, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOlGARBTIZSO",
        "outputId": "1f652692-b7bb-4310-d74a-f75b49a8cc8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "i,t=random_training_set()\n",
        "len(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpiGObbBX0Mr"
      },
      "source": [
        "---\n",
        "\n",
        "## Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "We now want to be able to train our network, and sample text after training.\n",
        "\n",
        "This function outlines how training a sequence style network goes. \n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ALC3Pf8Kbsi"
      },
      "source": [
        "# hidden_size_default = 200 # This is the dimension of our embedding space\n",
        "# It's a hyper-parameter that we can tune as we like\n",
        "\n",
        "\n",
        "def train(inp, target):\n",
        "  \"\"\" \n",
        "  Parameters:\n",
        "    both are token-tensors generated by the char_tensor fcn\n",
        "      (and returned by the random_training_set fcn)\n",
        "  \"\"\"\n",
        "  ## initialize hidden layers, set up gradient and loss \n",
        "  \n",
        "  decoder_optimizer.zero_grad()\n",
        "  hidden = decoder.init_hidden()\n",
        "  loss = 0\n",
        "  \n",
        "  # more stuff here...\n",
        "  for inp_char, target_char in zip(inp,target):\n",
        "    y_hat, hidden = decoder.forward(inp_char,hidden) # Note: y_hat is like a prob'ty dist'n\n",
        "    target_char = target_char.unsqueeze(0) # Note: target_char is like an integer\n",
        "    loss += criterion(y_hat, target_char)\n",
        "  \n",
        "  loss.backward()\n",
        "  decoder_optimizer.step()\n",
        "  \n",
        "  return loss\n",
        "  \n",
        "  \n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EN06NUu3YRlz"
      },
      "source": [
        "---\n",
        "\n",
        "## Sample text and Training information\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-bp-OZ1KjNh"
      },
      "source": [
        "def evaluate(prime_str='A', predict_len=100, temperature=0.8):\n",
        "  ## initialize hidden variable, initialize other useful variables \n",
        "  # Get an initial hidden state \n",
        "  hidden = decoder.init_hidden()\n",
        "  list_of_tokens = [char for char in prime_str]\n",
        "  \n",
        "  for char in prime_str:\n",
        "    inp = char_tensor(prime_str[-1])\n",
        "    out_vec, hidden = decoder.forward(inp,hidden)\n",
        "  \n",
        "  # Take the final out_vec and calculate the char from it \n",
        "  out = torch.multinomial(out_vec/sum(out_vec), 1)\n",
        "  list_of_tokens.append(all_characters[int(out)])\n",
        "  \n",
        "  # Now we take that output char and keep generating based on that\n",
        "  inp = Variable( out.long().cuda() )\n",
        "  for _ in range(predict_len-1):\n",
        "    # Find a tensor token to pass through the model\n",
        "    out_vec, hidden = decoder.forward(inp,hidden)\n",
        "    \n",
        "    # Now let's get the out_vec to look like a probability dist'n\n",
        "    out_vec = softmax( torch.exp(out_vec/temperature) )\n",
        "    # Convert to a single number by sampling\n",
        "    out = torch.multinomial(out_vec, 1)\n",
        "    # Append to the list \n",
        "    list_of_tokens.append(all_characters[int(out)])\n",
        "    # Update\n",
        "    inp = Variable( out.long() )\n",
        "    \n",
        "  return ''.join(list_of_tokens)\n",
        "  ## /\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFS2bpHSZEU6"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "## Run it and generate some text!\n",
        "\n",
        "---\n",
        "\n",
        "Assuming everything has gone well, you should be able to run the main function in the scaffold code, using either your custom GRU cell or the built in layer, and see output something like this. Using chunk_length=200, hidden_size=100 for 2000 epochs gave.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nXFeCmdKodw"
      },
      "source": [
        "import time\n",
        "n_epochs = 4000 # 5000\n",
        "print_every = 200\n",
        "plot_every = 10\n",
        "hidden_size = 400\n",
        "n_layers = 1\n",
        "dim_vocab = 100\n",
        "logsoftmax = nn.LogSoftmax(dim=1)\n",
        "softmax = nn.Softmax(dim=1)\n",
        "lr = 0.001\n",
        " \n",
        "decoder = RNN(n_characters, hidden_size, n_characters, dim_vocab=dim_vocab, n_layers=n_layers)\n",
        "decoder.cuda()\n",
        "decoder_optimizer = torch.optim.Adam(decoder.parameters(), lr=lr)\n",
        "criterion = nn.CrossEntropyLoss().cuda()\n",
        " \n",
        "start = time.time()\n",
        "all_losses = []\n",
        "loss_avg = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cipYAVPfW-71",
        "outputId": "f1db4b6b-0638-486d-8942-3d8eaf6eac1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "evaluate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'AK4KBh(JOn?p+Tt0\\r++P^ho\\\\mplP*=U\\rQZ<>zL `z<ZCc\\x0bC\\tKG_Wp*NBi*Lwsg.@<x42?bqhq5xUy|\\rs&|H >#/A7X Z\\tA>\\x0b%Bk\\\\5'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjbSSdzlV3I-",
        "outputId": "c23e71ef-2ea4-4dea-efb3-c761d2335772",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "emb_test = nn.Embedding(n_characters, dim_vocab).cuda()\n",
        "embd = emb_test(char_tensor(\"A\")).view(1, 1, -1)\n",
        "embdF = F.relu(embd)\n",
        "embdF.size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKfozqw-6eqb",
        "outputId": "b76c77e0-1b60-48a6-b15a-c7d4c82f911a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# n_epochs = 2000\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  loss_ = train(*random_training_set()) # Note we're passing two token tensors through train     \n",
        "  loss_avg += loss_\n",
        "\n",
        "  if epoch % print_every == 0:\n",
        "      print('[%s s (epoch %d %d%%) %.4f]' % (time.time() - start, epoch, epoch / n_epochs * 100, loss_/100.))\n",
        "      eval_str = evaluate('Wh',temperature=.2).replace('\\n','\\\\n')\n",
        "      print(eval_str, '\\n')\n",
        "\n",
        "  if epoch % plot_every == 0:\n",
        "      all_losses.append(loss_avg / plot_every)\n",
        "      loss_avg = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[104.2055287361145 s (epoch 200 5%) 4.4141]\n",
            "WhH the was the was the was the was the was the was the was the was the was the was the was the was th \n",
            "\n",
            "[208.13289618492126 s (epoch 400 10%) 3.8675]\n",
            "WhX his his his his his his his his his his his his his his his his his his his his his his his his hi \n",
            "\n",
            "[311.93042945861816 s (epoch 600 15%) 3.8104]\n",
            "WhAr so down and the was the could the was the was the was the was the could the was the was the was t \n",
            "\n",
            "[416.06379318237305 s (epoch 800 20%) 3.4703]\n",
            "Wh: said Scrooge and stoped the children and stoped the children and stoped the children and stoped th \n",
            "\n",
            "[519.8927199840546 s (epoch 1000 25%) 3.3508]\n",
            "WhZre to the wasted the wasted the wasted the\\nwasted the wasted the wasted the wasted the wasted the\\nw \n",
            "\n",
            "[624.4934210777283 s (epoch 1200 30%) 3.1558]\n",
            "Wh2us a should have been a should\\nhave been a sure and street in the was a see and stoped the was a sh \n",
            "\n",
            "[728.4678494930267 s (epoch 1400 35%) 3.2303]\n",
            "Wh0ing and state as the was the was the was the was the was the was the was the was the was the was th \n",
            "\n",
            "[830.6460132598877 s (epoch 1600 40%) 3.5776]\n",
            "Wh; and the struggle started to see the striet of the chied to see the chied to see the chied to see t \n",
            "\n",
            "[934.2823460102081 s (epoch 1800 45%) 2.9450]\n",
            "WhO dear the clerk with the specked to his nephew. \"He was not the same to his nephew. \"He was not the \n",
            "\n",
            "[1037.343005657196 s (epoch 2000 50%) 3.6372]\n",
            "Whing of the streets, and states of the streets,\\nand the street the street the street the streets, and \n",
            "\n",
            "[1139.4485819339752 s (epoch 2200 55%) 2.3554]\n",
            "Whch as the showed to the showed to the showed to the showed to the showed to the showed to the showed \n",
            "\n",
            "[1240.7184920310974 s (epoch 2400 60%) 2.3006]\n",
            "WhKless the could have been down the could have been\\nshadow of the country good of the country good of \n",
            "\n",
            "[1342.1863112449646 s (epoch 2600 65%) 3.0613]\n",
            "WhDed to the Ghost of the\\nthing to the Ghost of the tood of the tood of the first to the\\npeople with t \n",
            "\n",
            "[1443.7118277549744 s (epoch 2800 70%) 3.3880]\n",
            "Whd it was a strangest the course\\nthe course to his course to his course to his course of the same\\nsai \n",
            "\n",
            "[1545.619338274002 s (epoch 3000 75%) 2.7401]\n",
            "Wh\" said Scrooge of his\\ncold, and the first stood of his night, and stood the first stood\\nto him. The  \n",
            "\n",
            "[1647.5759694576263 s (epoch 3200 80%) 2.5092]\n",
            "Wh~ Scrooge had not\\nbell was the same to the same before her heart, and destribute the spectral hand.\\n \n",
            "\n",
            "[1749.358359336853 s (epoch 3400 85%) 3.1306]\n",
            "Wh_ed at the spectre with his\\ncondening in a bright his hands in the spectre with his\\ncondening in a b \n",
            "\n",
            "[1851.1893899440765 s (epoch 3600 90%) 2.5795]\n",
            "Whzer was a little business that believe\\nthe boy was a strange and in a brothers, and a children\\'s ch \n",
            "\n",
            "[1952.4929163455963 s (epoch 3800 95%) 2.7077]\n",
            "WhMressed the children it was\\nsurprise to be surerated for the pressed the children he saw a moment\\nmo \n",
            "\n",
            "[2054.1956355571747 s (epoch 4000 100%) 2.4639]\n",
            "Wh( as he was not a short, and he done\\nto the strong on the strong on the strong on the strong on the  \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQNIJwSw0Tz1",
        "outputId": "74a82f8e-21e7-4e07-b055-6d739d7c36b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        }
      },
      "source": [
        "CUDA_LAUNCH_BLOCKING=1\n",
        "from matplotlib import pyplot as plt\n",
        "print(all_losses[0].cpu().detach())\n",
        "plt.plot(all_losses)\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(748.4874)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee0so6aKJ5L8",
        "outputId": "cfe8ec7b-45ca-496f-9f0b-d705557fcbe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        }
      },
      "source": [
        "for i in range(10):\n",
        "  start_strings = [\" Th\", \" wh\", \" he\", \" I \", \" ca\", \" G\", \" lo\", \" ra\"]\n",
        "  start = random.randint(0,len(start_strings)-1)\n",
        "  print(start_strings[start])\n",
        "#   all_characters.index(string[c])\n",
        "  print(evaluate(start_strings[start], predict_len=200, temperature=2).replace('\\n','\\\\n'), '\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " lo\n",
            " lo.\\n\\n\"I will you see here it is not the Ghost, \"you don\\'t know what it was a laugh. It\\'s a great faith and many you have good a laugh. It was not a short, and he said, on it, you see him was his own,  \n",
            "\n",
            " ra\n",
            " raR and hope you see him was his own, to say\\na long as he said, and so looked at the fire, and having the strong on the strong one of the strong one of the things the door, and\\nstood out with a moment y \n",
            "\n",
            " ca\n",
            " ca\fed in the strong on the moment,\\nthe same of the strong on the town, or one of the family. The more he did so\\nmany coated on the office in the strong on the fire of which it was not a short,\\nfor the f \n",
            "\n",
            " ca\n",
            " caE |an you have been down at his own at the hungry\\nchange and hope you see him was his own at the strong one of the strong on the hallow\\nhe had not below his head. It was a shool of the moment,\\nthe one \n",
            "\n",
            " ra\n",
            " ra`ed to his face was not a large and happier of the moment,\\nthe spont. \"I have not to be not a heavy some off in!\"\\n\\nScrooge had a short of the hall in his head in the strong one of the strong one of th \n",
            "\n",
            " Th\n",
            " ThUse would have been for a man you have\\nbeen to some his own stool before him to say and done in the strong on the\\nthings the hall of the strong on the Project Gutenberg-tm License (any world have\\nbeen \n",
            "\n",
            " ca\n",
            " ca[ and have been a laugh.\\n\\n\"I have not to be light as he might have been a great as he asked him in the last of the moment, you may consequently.\\n\"And you see him was a man you have been for a moment,  \n",
            "\n",
            " G\n",
            " Gvent your so long as the same hands.\\nThe figure--on a man who had no rest and round the office in the more he\\nsaid, when he had not to bed a large and have looked at the strong one of the\\nchildren\\'s  \n",
            "\n",
            " wh\n",
            " whw should have been for a moment your stool before him with the heavy\\nWhat the shops of the strong on the town, or one of the moment,\\nthe door, and hope Joe in the town, or one stood one of the office  \n",
            "\n",
            " wh\n",
            " whd it was not before him in the strong on the most of the was heart, and\\nstood out of the things of the strong on the fire of a long as the Project Gutenberg-tm\\ncomforter stood out of the strong on the \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O3z6MeSwJAk-"
      },
      "source": [
        "The model does well in general. Loss went down over time. It's great at making English words, but not coherent sentences. Most of these are major word repetitions. As you can see, increasing the temperature to 2 yields much nicer, Dickens-like sentences than we saw printed during training."
      ]
    }
  ]
}